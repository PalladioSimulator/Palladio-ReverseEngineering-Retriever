# A GitHub Action that allows to run the Retriever on arbitrary GitHub repositories.

name: "Run Retriever"
description: |
  'Reverse-engineers a project''s source into a Palladio Component Model.
  Uploads the PCM as an artifact called `retriever`.
  Within that artifact, the PCM is located at the input `source_path`,
  e.g. for `source_path=MyProject/Repository` the output is `[retriever]/MyProject/Repository/repository.pcm`.'

inputs:
  source_path:
    description: "The location of the project to reverse-engineer"
    required: true
    default: "."
  rules:
    description: "The rules to reverse-engineer with, as a comma-separated list"
    required: true
    default: "org.palladiosimulator.retriever.extraction.rules.maven,org.palladiosimulator.retriever.extraction.rules.spring"
  rules_path:
    description: "The location of additional project specific rules"
    required: false
  benchmark:
    description: "Whether use hyperfine to benchmark the execution of the retriever, otherwise just the one time execution time is reported"
    required: false
    default: "false"
  analyze_vulnerabilities:
    description: "Whether use analyze vulnerabilities using snyk"
    required: false
    default: "false"
  snyk_token:
    description: "snyk API token"
    required: false
    default: ""
  nist_nvd_token:
    description: "NIST NVD API token"
    required: false
    default: ""

runs:
  using: "composite"
  steps:
    - name: Set Up JDK 17
      uses: actions/setup-java@v4
      with:
        distribution: "temurin"
        java-version: "17"

    - name: Create Temporary Directory
      shell: bash
      run: |
        TMP_DIR=$(mktemp -d)
        echo "tmp_dir=$TMP_DIR" >> $GITHUB_ENV
        mkdir $TMP_DIR/retriever_out

    - name: Get Action Version
      shell: bash
      # Assuming a format like in the GitHub Actions documentation:
      # /home/runner/work/_actions/repo-owner/name-of-action-repo/v1
      # There, the 7th segment is the action's tag. This is bumped up
      # to 8 since `cut` counts the empty string before the first / as well.
      run: |
        ACTION_VERSION=$(echo ${{ github.action_path }} | cut -d / -f 8- -)
        echo "action_version=$ACTION_VERSION" >>  $GITHUB_ENV

    - name: Determine Retriever Version
      shell: bash
      # Uses the latest Retriever or the Retriever with the same version that this action has
      run: |
        if [[ "${{ env.action_version }}" == "main" ]]; then
          echo "retriever=${{ github.api_url }}/repos/PalladioSimulator/Palladio-ReverseEngineering-Retriever/releases/latest" >> $GITHUB_ENV
        else
          echo "retriever=${{ github.api_url }}/repos/PalladioSimulator/Palladio-ReverseEngineering-Retriever/releases/tags/${{ env.action_version }}" >> $GITHUB_ENV
        fi

    - name: Gather Retriever Info
      shell: bash
      run: |
        RETRIEVER_INFO_FILE=${{ env.tmp_dir }}/retriever_out/retriever_info.md

        echo "RETRIEVER_INFO_FILE=$RETRIEVER_INFO_FILE" >> $GITHUB_ENV
        {
          echo "# [Retriever](https://github.com/PalladioSimulator/Palladio-ReverseEngineering-Retriever) Report"
          echo "| Version | Date |"
          echo "| ------- | ---- |"
          echo "| $(curl -sL "${{ env.retriever }}" | jq  -r ".tag_name") | $(date -u) |"
        } > $RETRIEVER_INFO_FILE

    - name: Gather Git Repository Info
      shell: bash
      run: |
        GIT_INFO_FILE="${{ env.tmp_dir }}/retriever_out/git_info.md"
        SOURCE_PATH="${{ github.workspace }}/${{ inputs.source_path }}"
        echo "GIT_INFO_FILE=$GIT_INFO_FILE" >> $GITHUB_ENV

        gather_git_info() {
          REPO_URL=$(git config --get remote.origin.url)
          BRANCH=$(git branch --show-current)
          COMMIT=$(git log -1 --pretty=format:"%H")

          REPO_PATH=$(echo $REPO_URL | sed -E 's/.*github\.com[:\/](.*)/\1/')
          OWNER=$(echo $REPO_PATH | cut -d'/' -f1)
          REPO_NAME=$(echo $REPO_PATH | cut -d'/' -f2 | sed 's/\.git$//')
          API_URL="https://api.github.com/repos/$OWNER/$REPO_NAME"

          # Get the number of commits using GitHub API and pagination info
          NUM_COMMITS=$(curl -s -I "${API_URL}/commits?per_page=1" | grep -i 'link:' | sed -E 's/.*page=([0-9]+)>; rel="last".*/\1/')
          NUM_STARS=$(curl -s $API_URL | jq '.stargazers_count // 0')
          NUM_CONTRIBUTORS=$(curl -s $API_URL/contributors | jq 'length // 0')

          echo "|      Attribute    | Value |"
          echo "| ----------------- | ----- |"
          echo "| Repository URL    | $REPO_URL |"
          echo "| Branch            | $BRANCH |"
          echo "| Commit            | $COMMIT |"
          echo "| Number of Commits | $NUM_COMMITS |"
          echo "| Stars             | $NUM_STARS |"
          echo "| Contributors      | $NUM_CONTRIBUTORS |"
          echo ""
        }

        print_header() {
          echo "## Git repository information"
        }

        # gather git repository information of the source directory or the containing directories
        if [ -d "$SOURCE_PATH/.git" ]; then
          cd "$SOURCE_PATH"
          print_header >> "$GIT_INFO_FILE"
          gather_git_info >> "$GIT_INFO_FILE"
        else
          FOUND_REPO=false
          for d in "$SOURCE_PATH"/*; do
            if [ -d "$d/.git" ]; then
              cd "$d"
              if [ "$FOUND_REPO" = false ]; then
                print_header >> "$GIT_INFO_FILE"
              fi
              gather_git_info >> "$GIT_INFO_FILE"
              FOUND_REPO=true
            fi
          done
          if [ "$FOUND_REPO" = false ]; then
            echo "no git repository found" > "$GIT_INFO_FILE"
          fi
        fi

    - name: Install Neofetch
      shell: bash
      run: sudo apt-get install -y neofetch

    - name: Gather Specific System Information with Neofetch
      shell: bash
      run: |
        SYSTEM_INFO_FILE=${{ env.tmp_dir }}/retriever_out/system_info.md
        echo "SYSTEM_INFO_FILE=$SYSTEM_INFO_FILE" >> $GITHUB_ENV
        {
          echo "## System information"
          echo "| Attribute | Value |"
          echo "| --------- | ----- |"
          neofetch os distro kernel cpu gpu memory --stdout | \
          sed -E 's/^(os): (.*)$/| OS | \2 |/; s/^(distro): (.*)$/| Distro | \2 |/; s/^(kernel): (.*)$/| Kernel | \2 |/; s/^(cpu): (.*)$/| CPU | \2 |/; s/^(gpu): (.*)$/| GPU | \2 |/; s/^(memory): (.*)$/| Memory | \2 |/'
        } > $SYSTEM_INFO_FILE

    - name: Install cloc
      shell: bash
      run: |
        sudo apt install cloc

    - name: Run cloc Analysis
      shell: bash
      run: |
        CLOC_INFO_FILE=${{ env.tmp_dir }}/retriever_out/cloc.md
        echo "CLOC_INFO_FILE=$CLOC_INFO_FILE" >> $GITHUB_ENV
        {
          echo "## Cloc analysis"
          cloc ${{ inputs.source_path }} --unicode --autoconf --diff-timeout 300 --docstring-as-code --read-binary-files --md --quiet | \
          sed -e '1d; 2s/cloc|github.com\/AlDanial\///; /^--- | ---$/d'
        } > $CLOC_INFO_FILE

    - name: Download Retriever
      shell: bash
      run: |
        # Set maximum retries
        max_retries=3
        attempt=0
        success=0

        while [ $attempt -lt $max_retries ]; do
            ((attempt=attempt+1))
            
            echo "Attempt $attempt of $max_retries..."
            
            # Execute the curl command and save its output
            output=$(curl --retry 3 -s ${{ env.retriever }})
            
            # Check for 'browser_download_url' (this is sometimes missing which causes an error -> retry)
            echo "$output" | grep 'browser_download_url' > /dev/null
            if [ $? -eq 0 ]; then
                # If found, use the URL to download the file with wget
                echo "$output" | grep -E 'browser_download_url' \
                | grep linux \
                | grep x86_64 \
                | grep -Eo 'https://[^\"]*' \
                | xargs wget -O "${{ env.tmp_dir }}/retriever.zip"
                
                success=1
                break # Exit loop on success
            else
                echo "URL not found, retrying..."
                sleep 5 
            fi
        done

        # Check if the download was successful
        if [ $success -ne 1 ]; then
            echo "Failed to find the download URL after $max_retries attempts."
            exit 1
        fi

    - name: Extract Retriever
      shell: bash
      working-directory: ${{ env.tmp_dir }}
      run: unzip retriever.zip -d retriever

    - name: Install hyperfine
      if: inputs.benchmark == 'true'
      shell: bash
      run: |
        wget https://github.com/sharkdp/hyperfine/releases/download/v1.16.1/hyperfine_1.16.1_amd64.deb
        sudo dpkg -i hyperfine_1.16.1_amd64.deb
  
    - name: Install snyk
      if: inputs.analyze_vulnerabilities == 'true'
      shell: bash
      run: |
        curl --compressed https://static.snyk.io/cli/latest/snyk-linux -o snyk
        chmod +x ./snyk
        mv ./snyk /usr/local/bin/
        snyk auth ${{ inputs.snyk_token }}

    - name: Prepare Retriever Command
      shell: bash
      env:
        RETRIEVER_COMMAND: './eclipse -nosplash -i "${{ github.workspace }}/${{ inputs.source_path }}" -o "${{ env.tmp_dir }}/eclipse_tmp" -r "${{ inputs.rules }}"'
      run: |
        if [[ "${{ inputs.rules_path }}" != '' ]]; then
          RETRIEVER_COMMAND="${RETRIEVER_COMMAND} -x \"${{ github.workspace }}/${{ inputs.rules_path }}\""
        fi
        if [[ "${{ inputs.analyze_vulnerabilities }}" == 'true' ]]; then
          RETRIEVER_COMMAND="${RETRIEVER_COMMAND} -a /usr/local/bin/snyk"
        fi
        echo "retriever_command=$RETRIEVER_COMMAND" >> $GITHUB_ENV

    - name: Execute Retriever
      shell: bash
      working-directory: ${{ env.tmp_dir }}/retriever
      env:
        NO_AT_BRIDGE: 1 # avoid eclipse error "AT-SPI: Error retrieving accessibility bus address"
        TIMING_INFO_FILE: ${{ env.tmp_dir }}/retriever_out/timing.md
        NIST_NVD_API_KEY: ${{ inputs.nist_nvd_token }}
      run: |
        echo "TIMING_INFO_FILE=$TIMING_INFO_FILE" >> $GITHUB_ENV
        mkdir "${{ env.tmp_dir }}/eclipse_tmp"
        echo "log4j.rootLogger=debug, stdout 
          log4j.appender.stdout=org.apache.log4j.ConsoleAppender 
          log4j.appender.stdout.layout=org.apache.log4j.PatternLayout 
          # Pattern to output the caller's file name and line number. 
          log4j.appender.stdout.layout.ConversionPattern=%5p [%t] (%F:%L) - %m%n" \
          > log4j.properties
        echo "log4j.configuration=file://${{ env.tmp_dir }}/retriever/log4j.properties" >> configuration/config.ini
        if [ "${{ inputs.benchmark }}" = "true" ]; then
          # Execute with Hyperfine
          hyperfine \
            --warmup 3 \
            --runs 10 \
            --show-output \
            --ignore-failure \
            --export-markdown $TIMING_INFO_FILE \
            --prepare 'sleep 1; \
            rm -rf "${{ env.tmp_dir }}/eclipse_tmp"; sleep 1; \
            rm -rf "${{ env.tmp_dir }}/retriever/workspace"; sleep 1; \
            echo "cleanup done"' \
            "${{ env.retriever_command }}"
          
          # Remove the first column from the table using sed
          sed -i 's/^[^|]*|[^|]*|/|/' $TIMING_INFO_FILE
          {
            echo "## Retriever execution time"
            cat $TIMING_INFO_FILE
          } > "${TIMING_INFO_FILE}.tmp" && mv "${TIMING_INFO_FILE}.tmp" "$TIMING_INFO_FILE"
                    
        else
          # Execute with /usr/bin/time
          /usr/bin/time -p -o "$TIMING_INFO_FILE" ${{ env.retriever_command }}
          # Read and reformat the timing information
          {
            echo "## Retriever execution time"
            echo "| Metric | Time (seconds) |"
            echo "| --- | ---: |"
            while IFS= read -r line; do
              case "$line" in
                real*) echo "| Real CPU Time | ${line#* } |" ;;
                user*) echo "| User CPU Time | ${line#* } |" ;;
                sys*) echo "| System CPU Time | ${line#* } |" ;;
              esac
            done < "$TIMING_INFO_FILE"
            echo "<!--"
            echo "Explainations:"
            echo "- __Real CPU Time__: actual time the command has run (can be less than total time spent in user and system mode for multi-threaded processes)"
            echo "- __User CPU Time__: time the command has spent running in user mode"
            echo "- __System CPU Time__: time the command has spent running in system or kernel mode"
            echo "-->"
          } > "${TIMING_INFO_FILE}.tmp" && mv "${TIMING_INFO_FILE}.tmp" "$TIMING_INFO_FILE"
        fi

        mv ${{ env.tmp_dir }}/eclipse_tmp/* ${{ env.tmp_dir }}/retriever_out/

    - name: Combine and Clean Up Files
      shell: bash
      run: |
        # Combine files into one, with empty lines between file contents
        {
          cat $RETRIEVER_INFO_FILE
          echo
          cat $GIT_INFO_FILE
          echo
          cat $SYSTEM_INFO_FILE
          echo
          cat $TIMING_INFO_FILE
          echo
          cat $CLOC_INFO_FILE
        } > ${{ env.tmp_dir }}/retriever_out/README.md
        # Delete the original files
        rm -f $RETRIEVER_INFO_FILE $GIT_INFO_FILE $SYSTEM_INFO_FILE $CLOC_INFO_FILE $TIMING_INFO_FILE

    - name: Prepare Analysis Results for Upload
      shell: bash
      working-directory: ${{ env.tmp_dir }}
      run: |
        mkdir -p tmp/${{ inputs.source_path }}
        mv retriever_out/* tmp/${{ inputs.source_path }}
        mv tmp/* retriever_out
        rmdir tmp

    - name: Upload Analysis Results
      uses: actions/upload-artifact@v3
      with:
        name: retriever
        path: ${{ env.tmp_dir }}/retriever_out

    - name: Prepare Eclipse Logs for Upload
      if: failure()
      shell: bash
      working-directory: ${{ env.tmp_dir }}
      run: |
        mkdir -p eclipse_logs/${{ inputs.source_path }}
        mv retriever/configuration/*.log retriever/workspace/.metadata/.log eclipse_logs/${{ inputs.source_path }}

    - name: Upload Eclipse Logs
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: eclipse_logs
        path: ${{ env.tmp_dir }}/eclipse_logs

    - name: Delete Temporary Directory
      if: always()
      shell: bash
      run: rm -rf ${{ env.tmp_dir }}
